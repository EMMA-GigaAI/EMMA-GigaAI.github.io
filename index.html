<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="EMMA: Generalizing Real-World Robot Manipulation via Generative Visual Transfer">
  <meta name="keywords" content="EMMA">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>EMMA: Generalizing Real-World Robot Manipulation via Generative Visual Transfer</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/ms_icon.png">

  <style>  
    table {  
      font-family: arial, sans-serif;  
      border-collapse: collapse;  
      width: 100%;  
    }  
      
    td, th {  
      border: 2px solid #F1F4F5;  
      text-align: left;  
      padding: 8px;  
    }  
    tr:nth-child(3n - 1) {  
      background-color: #F1F4F5;  
    }  

    tr:nth-child(3n) {  
      border: 2px solid #FFFFFF;
    }  
  </style>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">EMMA: Generalizing Real-World Robot Manipulation via Generative Visual Transfer </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a >Zhehao Dong</a><sup>1,2*</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=96lsfiUAAAAJ&hl">Xiaofeng Wang</a><sup>1,3*</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=NmwjI0AAAAAJ&hl">Zheng Zhu</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a >Yirui Wang </a><sup>3</sup>,</span>
            <span class="author-block">
              <a >Yang Wang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a >Yukun Zhou</a><sup>1</sup>,</span>
            <span class="author-block">
              <a >Boyuan Wang</a><sup>1,4</sup>,</span>
            <span class="author-block">
              <a >Chaojun Ni</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a >Runqi Ouyang</a><sup>1,4</sup>,</span>
            <span class="author-block">
              <a >Wenkang Qin</a><sup>1</sup>,</span>
            <span class="author-block">
              <a >Xinze Chen</a><sup>1</sup>,</span>
            <span class="author-block">
              <a >Yun Ye</a><sup>1</sup>,</span>
            <span class="author-block">
              <a >Guan Huang</a><sup>1</sup>,</span>
            </span><br>

          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">GigaAI<sup>1</sup>,</span>&nbsp;
            <span class="author-block">Peking University<sup>2</sup></span>&nbsp;
            <span class="author-block">Tsinghua University<sup>3</sup></span>&nbsp;
            <span class="author-block">CASIA<sup>4</sup></span>&nbsp;
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup>Equal Contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2509.22407"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/VittorioDong/EMMA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <img id="teaser" autoplay muted loop playsinline height="100%" src="./static/images/abs.png" style="width:100%;height:100%;">
      <p  style="font-size: 16px;"> 
        DreamTransfer demonstrates strong controllability in embodied manipulation video generation. It excels in text-controlled appearance editing while preserving 3D structure and geometric plausibility, and supports both real-to-real and sim-to-real transfer. The complete prompts used for generation is provided in the supplementary materials.
      </p>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Vision-language-action (VLA) models increasingly rely on diverse training data to achieve robust generalization. 
            However, collecting large-scale real-world robot manipulation data across varied object appearances and environmental conditions 
            remains prohibitively time-consuming and expensive. To overcome this bottleneck, we propose Embodied Manipulation Media Adaptation (EMMA), 
            a VLA policy enhancement framework that integrates a generative data engine with an effective training pipeline. 
            We introduce DreamTransfer, a diffusion Transformer-based framework for generating multi-view consistent, 
            geometrically grounded embodied manipulation videos. DreamTransfer enables text-controlled visual editing of robot videos, 
            transforming foreground, background, and lighting conditions without compromising 3D structure or geometrical plausibility. 
            Furthermore, we explore hybrid training with real and generated data, and introduce AdaMix, a hard-sample-aware training 
            strategy that dynamically reweights training batches to focus optimization on perceptually or kinematically challenging samples. 
            Extensive experiments show that videos generated by DreamTransfer significantly outperform prior video generation methods 
            in multi-view consistency, geometric fidelity, and text-conditioning accuracy. Crucially, VLAs trained with generated data enable 
            robots to generalize to unseen object categories and novel visual domains using only demonstrations from a single appearance. 
            In real-world robotic manipulation tasks with zero-shot visual domains, our approach achieves over a 200% relative performance 
            gain compared to training on real data alone, and further improves by 13% with AdaMix, demonstrating its effectiveness in boosting 
            policy generalization.
          </p>
        </div> 
      </div>
    </div>
    <!--/ Abstract. -->


  </div>
</section>


<section class="section" id="Method">
  <div class="container is-max-desktop content">
    <h2 class="title">Method</h2>
    <section class="hero method">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <img id="method" autoplay muted loop playsinline height="100%" src="./static/images/method.png" style="width:100%;height:100%;">
          <p>
            Overview of the EMMA framework. First, DreamTransfer generates multi-view consistent videos by performing text-controlled visual editing of the foreground, background, and lighting conditions, conditioned on depth and corresponding text prompts. The generated videos are then evaluated by a video quality filter. Low-quality videos are initially assigned zero sampling weight to stabilize early-stage training. The AdaMix module further adaptively reweights training samples based on trajectory performance metrics, up-weighting challenging samples to improve policy robustness and generalization.
			<!--/
            Method overview: Starting from a randomly sampled latent code <span class="math inline">\(x_{T}^{1}\)</span>, we apply <span class="math inline">\(\Delta t\)</span> DDIM backward steps to obtain <span class="math inline">\(x_{T'}^{1}\)</span> using a pre-trained Stable Diffusion model (SD). A specified motion field results for each frame <span class="math inline">\(k\)</span> in a warping function <span class="math inline">\(W_k\)</span> that turns <span class="math inline">\(x_{T'}^{1}\)</span> to <span class="math inline">\(x_{T'}^{k}\)</span>. By enhancing the latent codes with motion dynamics, we determine the global scene and camera motion and achieve temporal consistency in the background and the global scene.
            A subsequent DDPM forward application delivers latent codes <span class="math inline">\(x_{T}^{k}\)</span> for <span class="math inline">\(k=1,\ldots,m\)</span>. By using the (probabilistic) DDPM method, a greater degree of freedom is achieved with respect to the motion of objects.
            Finally, the latent codes are passed to our modified SD model using the proposed cross-frame attention, which uses keys and values from the first frame to generate the image of frame <span class="math inline">\(k=1,\ldots,m\)</span>. By using cross-frame attention,  the appearance and the identity of the foreground object are preserved  throughout the sequence. 
            Optionally, we apply background smoothing. To this end, we employ salient object detection to obtain for each frame <span class="math inline">\(k\) a mask <span class="math inline">\(M^{k}\)</span> indicating the foreground pixels. Finally, for the background (using the mask <span class="math inline">\(M^{k}\)</span>), a convex combination between the latent code <span class="math inline">\(x_{t}^{1}\)</span> of frame one warped to frame <span class="math inline">\(k\)</span> and the latent code <span class="math inline">\(x_{t}^{k}\)</span> is used to further improve the temporal consistency of the background.-->
          </p>
        </div>
      </div>
    </section>
  </div>
</section>


<section class="section" id="Results">
  <div class="container is-max-desktop content">
    <h2 class="title">Results</h2>
    <section class="hero method">
    <div class="container is-max-desktop">
    <div class="hero-body">  

  <h4 class="title">1. Embodied manipulation video generation.</h4>
    <div class="container is-max-desktop">
      <div style="display: flex; justify-content: center; gap: 10px; flex-wrap: wrap; text-align: center; margin: 0 auto;">
        <!-- 视频 1 -->
        <div style="flex: 1; min-width: 200px;">
          <video autoplay muted loop controls style="width: 100%; height: auto; display: block;">
            <source src="./static/videos/dreamtransfer_fold_cloth.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
        <!-- 视频 2 -->
        <div style="flex: 1; min-width: 200px;">
          <video autoplay muted loop controls style="width: 100%; height: auto; display: block;">
            <source src="./static/videos/dreamtransfer_clean_desk.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
        <!-- 视频 3 -->
        <div style="flex: 1; min-width: 200px;">
          <video autoplay muted loop controls style="width: 100%; height: auto; display: block;">
            <source src="./static/videos/dreamtransfer_throw_bottle.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      </div>
    </div>
    <br>
    <p style="margin-bottom: 30px;"></p>

  <h4 class="title">2. Real-world deployment of AdaMix-trained policies on "Fold Cloth".</h4>
    <div class="container is-max-desktop">
      <div style="display: flex; justify-content: center; gap: 10px; flex-wrap: wrap; text-align: center; margin: 0 auto;">
        <!-- 视频 1 -->
        <div style="flex: 1; min-width: 200px;">
          <video autoplay muted loop controls style="width: 100%; height: auto; display: block;">
            <source src="./static/videos/fold_cloth/fold_cloth_1.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
        <!-- 视频 2 -->
        <div style="flex: 1; min-width: 200px;">
          <video autoplay muted loop controls style="width: 100%; height: auto; display: block;">
            <source src="./static/videos/fold_cloth/fold_cloth_2.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
        <!-- 视频 3 -->
        <div style="flex: 1; min-width: 200px;">
          <video autoplay muted loop controls style="width: 100%; height: auto; display: block;">
            <source src="./static/videos/fold_cloth/fold_cloth_3.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
        <!-- 视频 4 -->
        <div style="flex: 1; min-width: 200px;">
          <video autoplay muted loop controls style="width: 100%; height: auto; display: block;">
            <source src="./static/videos/fold_cloth/fold_cloth_4.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      </div>
    </div>
    <br>
    <p style="margin-bottom: 30px;"></p>

    <h4 class="title">3. Real-world deployment of AdaMix-trained policies on "Clean Desk".</h4>
    <div class="container is-max-desktop">
      <div style="display: flex; justify-content: center; gap: 10px; flex-wrap: wrap; text-align: center; margin: 0 auto;">
        <!-- 视频 1 -->
        <div style="flex: 1; min-width: 200px;">
          <video autoplay muted loop controls style="width: 100%; height: auto; display: block;">
            <source src="./static/videos/clean_desk/clean_desk_1.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
        <!-- 视频 2 -->
        <div style="flex: 1; min-width: 200px;">
          <video autoplay muted loop controls style="width: 100%; height: auto; display: block;">
            <source src="./static/videos/clean_desk/clean_desk_2.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
        <!-- 视频 3 -->
        <div style="flex: 1; min-width: 200px;">
          <video autoplay muted loop controls style="width: 100%; height: auto; display: block;">
            <source src="./static/videos/clean_desk/clean_desk_3.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
        <!-- 视频 4 -->
        <div style="flex: 1; min-width: 200px;">
          <video autoplay muted loop controls style="width: 100%; height: auto; display: block;">
            <source src="./static/videos/clean_desk/clean_desk_4.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      </div>
    </div>
    <br>
    <p style="margin-bottom: 30px;"></p>

    <h4 class="title">4. Real-world deployment of AdaMix-trained policies on "Throw Bottle".</h4>
    <div class="container is-max-desktop">
      <div style="display: flex; justify-content: center; gap: 10px; flex-wrap: wrap; text-align: center; margin: 0 auto;">
        <!-- 视频 1 -->
        <div style="flex: 1; min-width: 200px;">
          <video autoplay muted loop controls style="width: 100%; height: auto; display: block;">
            <source src="./static/videos/throw_bottle/throw_bottle_1.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
        <!-- 视频 2 -->
        <div style="flex: 1; min-width: 200px;">
          <video autoplay muted loop controls style="width: 100%; height: auto; display: block;">
            <source src="./static/videos/throw_bottle/throw_bottle_2.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
        <!-- 视频 3 -->
        <div style="flex: 1; min-width: 200px;">
          <video autoplay muted loop controls style="width: 100%; height: auto; display: block;">
            <source src="./static/videos/throw_bottle/throw_bottle_3.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
        <!-- 视频 4 -->
        <div style="flex: 1; min-width: 200px;">
          <video autoplay muted loop controls style="width: 100%; height: auto; display: block;">
            <source src="./static/videos/throw_bottle/throw_bottle_4.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      </div>
    </div>
    <br>
    <p style="margin-bottom: 30px;"></p>

  </div></div></section>
  </div>
</section>

	
	
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <p> If you use our work in your research, please cite: </p>
    <pre><code>@article{dong2025emma,
  title={EMMA: Generalizing Real-World Robot Manipulation via Generative Visual Transfer},
  author={Zhehao Dong and Xiaofeng Wang and Zheng Zhu and Yirui Wang and Yang Wang and Yukun Zhou and Boyuan Wang and Chaojun Ni and Runqi Ouyang and Wenkang Qin and Xinze Chen and Yun Ye and Guan Huang},
  journal={arXiv preprint arXiv:2509.22407},
  year={2025}
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/VittorioDong/EMMA" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website adapted from the following <a href="https://github.com/nerfies/nerfies.github.io">template</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
